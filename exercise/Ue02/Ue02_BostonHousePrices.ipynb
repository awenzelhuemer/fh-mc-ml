{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\ncount  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \nmean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \nstd      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \nmin      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \nmax     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n\n              AGE         DIS         RAD         TAX     PTRATIO           B  \\\ncount  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \nmean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \nstd     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \nmin      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \nmax    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n\n            LSTAT        MEDV  \ncount  506.000000  506.000000  \nmean    12.653063   22.532806  \nstd      7.141062    9.197104  \nmin      1.730000    5.000000  \n25%      6.950000   17.025000  \n50%     11.360000   21.200000  \n75%     16.955000   25.000000  \nmax     37.970000   50.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n      <th>MEDV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.613524</td>\n      <td>11.363636</td>\n      <td>11.136779</td>\n      <td>0.069170</td>\n      <td>0.554695</td>\n      <td>6.284634</td>\n      <td>68.574901</td>\n      <td>3.795043</td>\n      <td>9.549407</td>\n      <td>408.237154</td>\n      <td>18.455534</td>\n      <td>356.674032</td>\n      <td>12.653063</td>\n      <td>22.532806</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.601545</td>\n      <td>23.322453</td>\n      <td>6.860353</td>\n      <td>0.253994</td>\n      <td>0.115878</td>\n      <td>0.702617</td>\n      <td>28.148861</td>\n      <td>2.105710</td>\n      <td>8.707259</td>\n      <td>168.537116</td>\n      <td>2.164946</td>\n      <td>91.294864</td>\n      <td>7.141062</td>\n      <td>9.197104</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.006320</td>\n      <td>0.000000</td>\n      <td>0.460000</td>\n      <td>0.000000</td>\n      <td>0.385000</td>\n      <td>3.561000</td>\n      <td>2.900000</td>\n      <td>1.129600</td>\n      <td>1.000000</td>\n      <td>187.000000</td>\n      <td>12.600000</td>\n      <td>0.320000</td>\n      <td>1.730000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.082045</td>\n      <td>0.000000</td>\n      <td>5.190000</td>\n      <td>0.000000</td>\n      <td>0.449000</td>\n      <td>5.885500</td>\n      <td>45.025000</td>\n      <td>2.100175</td>\n      <td>4.000000</td>\n      <td>279.000000</td>\n      <td>17.400000</td>\n      <td>375.377500</td>\n      <td>6.950000</td>\n      <td>17.025000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.256510</td>\n      <td>0.000000</td>\n      <td>9.690000</td>\n      <td>0.000000</td>\n      <td>0.538000</td>\n      <td>6.208500</td>\n      <td>77.500000</td>\n      <td>3.207450</td>\n      <td>5.000000</td>\n      <td>330.000000</td>\n      <td>19.050000</td>\n      <td>391.440000</td>\n      <td>11.360000</td>\n      <td>21.200000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.677083</td>\n      <td>12.500000</td>\n      <td>18.100000</td>\n      <td>0.000000</td>\n      <td>0.624000</td>\n      <td>6.623500</td>\n      <td>94.075000</td>\n      <td>5.188425</td>\n      <td>24.000000</td>\n      <td>666.000000</td>\n      <td>20.200000</td>\n      <td>396.225000</td>\n      <td>16.955000</td>\n      <td>25.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>88.976200</td>\n      <td>100.000000</td>\n      <td>27.740000</td>\n      <td>1.000000</td>\n      <td>0.871000</td>\n      <td>8.780000</td>\n      <td>100.000000</td>\n      <td>12.126500</td>\n      <td>24.000000</td>\n      <td>711.000000</td>\n      <td>22.000000</td>\n      <td>396.900000</td>\n      <td>37.970000</td>\n      <td>50.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('housing.csv', sep=\"\\s+\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "features = df[[\"CRIM\",\"ZN\",\"INDUS\",\"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\"RAD\",\"TAX\",\"PTRATIO\",\"B\",\"LSTAT\"]]\n",
    "prices = df['MEDV']\n",
    "\n",
    "#print(prices)\n",
    "#print(features)\n",
    "\n",
    "# splitting the dataframe into train and test sets\n",
    "X_train,X_test,y_train,y_test = train_test_split(\n",
    "  features,prices,test_size=0.30,random_state=57)\n",
    "\n",
    "#print(X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7388646397632683\n",
      "[-1.10777604e-01  4.52134626e-02  3.81363044e-02  2.51757184e+00\n",
      " -1.83429585e+01  4.10455395e+00 -1.21264094e-02 -1.55004181e+00\n",
      "  2.75418027e-01 -1.04526307e-02 -9.46944901e-01  6.12865467e-03\n",
      " -5.48969244e-01]\n",
      "36.7890343362636\n",
      "0.7353138568159987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "print(reg.score(X_train, y_train))\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)\n",
    "pred = reg.predict(X_test)\n",
    "\n",
    "score = reg.score(X_test, y_test)\n",
    "print(score)\n",
    "\n",
    "#print(np.vstack((pred,y_test.values)).T)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Polynomial Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8746976220255396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(X_train)\n",
    "\n",
    "poly_reg_model = LinearRegression()\n",
    "poly_reg_model.fit(poly_features, y_train)\n",
    "\n",
    "test_poly_features = poly.fit_transform(X_test)\n",
    "y_predicted = poly_reg_model.predict(test_poly_features)\n",
    "\n",
    "score = poly_reg_model.score(test_poly_features, y_test)\n",
    "print(score)\n",
    "\n",
    "#print(np.vstack((y_predicted,y_test.values)).T)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 14 candidates, totalling 140 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=KFold(n_splits=10, random_state=100, shuffle=True),\n             estimator=RFE(estimator=LinearRegression()),\n             param_grid=[{'n_features_to_select': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n                                                   10, 11, 12, 13, 14]}],\n             return_train_score=True, scoring='r2', verbose=1)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "folds = KFold(n_splits = 10, shuffle = True, random_state = 100)\n",
    "\n",
    "# step-2: specify range of hyperparameters to tune\n",
    "hyper_params = [{'n_features_to_select': list(range(1, 14))}]\n",
    "\n",
    "\n",
    "# step-3: perform grid search\n",
    "# 3.1 specify model\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "rfe = RFE(lm)\n",
    "\n",
    "# 3.2 call GridSearchCV()\n",
    "model_cv = GridSearchCV(estimator = rfe,\n",
    "                        param_grid = hyper_params,\n",
    "                        scoring= 'r2',\n",
    "                        cv = folds,\n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)\n",
    "\n",
    "# fit the model\n",
    "model_cv.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0        0.014198      0.004260         0.002696        0.000638   \n1        0.015200      0.004916         0.002902        0.000946   \n2        0.012495      0.005143         0.002601        0.001020   \n3        0.010700      0.002688         0.002298        0.000455   \n4        0.009202      0.001832         0.003000        0.001260   \n5        0.010902      0.001814         0.002600        0.000663   \n6        0.009207      0.001330         0.003094        0.001758   \n7        0.008405      0.002007         0.002295        0.000461   \n8        0.006892      0.001511         0.002499        0.000673   \n9        0.006702      0.001735         0.003200        0.002963   \n10       0.006095      0.001443         0.002601        0.000802   \n11       0.003996      0.000630         0.002201        0.000401   \n12       0.004291      0.001499         0.002099        0.000538   \n13       0.003495      0.000804         0.002302        0.000645   \n\n   param_n_features_to_select                        params  \\\n0                           1   {'n_features_to_select': 1}   \n1                           2   {'n_features_to_select': 2}   \n2                           3   {'n_features_to_select': 3}   \n3                           4   {'n_features_to_select': 4}   \n4                           5   {'n_features_to_select': 5}   \n5                           6   {'n_features_to_select': 6}   \n6                           7   {'n_features_to_select': 7}   \n7                           8   {'n_features_to_select': 8}   \n8                           9   {'n_features_to_select': 9}   \n9                          10  {'n_features_to_select': 10}   \n10                         11  {'n_features_to_select': 11}   \n11                         12  {'n_features_to_select': 12}   \n12                         13  {'n_features_to_select': 13}   \n13                         14  {'n_features_to_select': 14}   \n\n    split0_test_score  split1_test_score  split2_test_score  \\\n0            0.166317           0.294888           0.239434   \n1            0.366526           0.554087           0.790403   \n2            0.450767           0.502259           0.820038   \n3            0.531377           0.670496           0.797558   \n4            0.555476           0.691897           0.737369   \n5            0.736166           0.708157           0.777945   \n6            0.719465           0.695793           0.775019   \n7            0.714166           0.671223           0.775634   \n8            0.712160           0.673564           0.769910   \n9            0.710441           0.681532           0.781997   \n10           0.709272           0.678405           0.775438   \n11           0.706787           0.683852           0.776975   \n12           0.720316           0.667979           0.777476   \n13           0.720316           0.667979           0.777476   \n\n    split3_test_score  ...  split2_train_score  split3_train_score  \\\n0            0.065389  ...            0.165113            0.180048   \n1            0.575035  ...            0.508318            0.527203   \n2            0.599901  ...            0.531052            0.550538   \n3            0.683637  ...            0.599926            0.610771   \n4            0.621166  ...            0.621918            0.632725   \n5            0.755290  ...            0.712722            0.715455   \n6            0.758520  ...            0.715199            0.717462   \n7            0.758417  ...            0.722086            0.724369   \n8            0.755378  ...            0.723088            0.725160   \n9            0.756918  ...            0.725956            0.728834   \n10           0.756005  ...            0.730828            0.729382   \n11           0.757888  ...            0.731083            0.733510   \n12           0.754316  ...            0.733979            0.736713   \n13           0.754316  ...            0.733979            0.736713   \n\n    split4_train_score  split5_train_score  split6_train_score  \\\n0             0.174800            0.171037            0.185811   \n1             0.506714            0.526405            0.571889   \n2             0.529450            0.555455            0.590120   \n3             0.590427            0.617221            0.659561   \n4             0.605462            0.628820            0.671704   \n5             0.705317            0.713190            0.749315   \n6             0.706869            0.715224            0.750409   \n7             0.713732            0.723439            0.752675   \n8             0.714349            0.724586            0.752894   \n9             0.717969            0.727255            0.755867   \n10            0.718551            0.728120            0.757035   \n11            0.723233            0.730462            0.761431   \n12            0.724424            0.733250            0.763980   \n13            0.724424            0.733250            0.763980   \n\n    split7_train_score  split8_train_score  split9_train_score  \\\n0             0.162002            0.190277            0.172008   \n1             0.551647            0.512415            0.542829   \n2             0.578030            0.541063            0.564203   \n3             0.637768            0.601148            0.626075   \n4             0.652404            0.617932            0.643605   \n5             0.732745            0.702732            0.738184   \n6             0.733976            0.705980            0.740035   \n7             0.738797            0.713807            0.744390   \n8             0.743385            0.714536            0.748083   \n9             0.743506            0.718483            0.748130   \n10            0.747680            0.719197            0.750452   \n11            0.752822            0.725036            0.753351   \n12            0.753029            0.726660            0.753366   \n13            0.753029            0.726660            0.753366   \n\n    mean_train_score  std_train_score  \n0           0.172092         0.010209  \n1           0.531621         0.019558  \n2           0.555306         0.018149  \n3           0.617197         0.019113  \n4           0.633595         0.017740  \n5           0.719991         0.014345  \n6           0.722226         0.013842  \n7           0.728667         0.012203  \n8           0.730064         0.012842  \n9           0.732804         0.011920  \n10          0.734451         0.012394  \n11          0.738302         0.012381  \n12          0.740307         0.012091  \n13          0.740307         0.012091  \n\n[14 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_n_features_to_select</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>...</th>\n      <th>split2_train_score</th>\n      <th>split3_train_score</th>\n      <th>split4_train_score</th>\n      <th>split5_train_score</th>\n      <th>split6_train_score</th>\n      <th>split7_train_score</th>\n      <th>split8_train_score</th>\n      <th>split9_train_score</th>\n      <th>mean_train_score</th>\n      <th>std_train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.014198</td>\n      <td>0.004260</td>\n      <td>0.002696</td>\n      <td>0.000638</td>\n      <td>1</td>\n      <td>{'n_features_to_select': 1}</td>\n      <td>0.166317</td>\n      <td>0.294888</td>\n      <td>0.239434</td>\n      <td>0.065389</td>\n      <td>...</td>\n      <td>0.165113</td>\n      <td>0.180048</td>\n      <td>0.174800</td>\n      <td>0.171037</td>\n      <td>0.185811</td>\n      <td>0.162002</td>\n      <td>0.190277</td>\n      <td>0.172008</td>\n      <td>0.172092</td>\n      <td>0.010209</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.015200</td>\n      <td>0.004916</td>\n      <td>0.002902</td>\n      <td>0.000946</td>\n      <td>2</td>\n      <td>{'n_features_to_select': 2}</td>\n      <td>0.366526</td>\n      <td>0.554087</td>\n      <td>0.790403</td>\n      <td>0.575035</td>\n      <td>...</td>\n      <td>0.508318</td>\n      <td>0.527203</td>\n      <td>0.506714</td>\n      <td>0.526405</td>\n      <td>0.571889</td>\n      <td>0.551647</td>\n      <td>0.512415</td>\n      <td>0.542829</td>\n      <td>0.531621</td>\n      <td>0.019558</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.012495</td>\n      <td>0.005143</td>\n      <td>0.002601</td>\n      <td>0.001020</td>\n      <td>3</td>\n      <td>{'n_features_to_select': 3}</td>\n      <td>0.450767</td>\n      <td>0.502259</td>\n      <td>0.820038</td>\n      <td>0.599901</td>\n      <td>...</td>\n      <td>0.531052</td>\n      <td>0.550538</td>\n      <td>0.529450</td>\n      <td>0.555455</td>\n      <td>0.590120</td>\n      <td>0.578030</td>\n      <td>0.541063</td>\n      <td>0.564203</td>\n      <td>0.555306</td>\n      <td>0.018149</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.010700</td>\n      <td>0.002688</td>\n      <td>0.002298</td>\n      <td>0.000455</td>\n      <td>4</td>\n      <td>{'n_features_to_select': 4}</td>\n      <td>0.531377</td>\n      <td>0.670496</td>\n      <td>0.797558</td>\n      <td>0.683637</td>\n      <td>...</td>\n      <td>0.599926</td>\n      <td>0.610771</td>\n      <td>0.590427</td>\n      <td>0.617221</td>\n      <td>0.659561</td>\n      <td>0.637768</td>\n      <td>0.601148</td>\n      <td>0.626075</td>\n      <td>0.617197</td>\n      <td>0.019113</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.009202</td>\n      <td>0.001832</td>\n      <td>0.003000</td>\n      <td>0.001260</td>\n      <td>5</td>\n      <td>{'n_features_to_select': 5}</td>\n      <td>0.555476</td>\n      <td>0.691897</td>\n      <td>0.737369</td>\n      <td>0.621166</td>\n      <td>...</td>\n      <td>0.621918</td>\n      <td>0.632725</td>\n      <td>0.605462</td>\n      <td>0.628820</td>\n      <td>0.671704</td>\n      <td>0.652404</td>\n      <td>0.617932</td>\n      <td>0.643605</td>\n      <td>0.633595</td>\n      <td>0.017740</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.010902</td>\n      <td>0.001814</td>\n      <td>0.002600</td>\n      <td>0.000663</td>\n      <td>6</td>\n      <td>{'n_features_to_select': 6}</td>\n      <td>0.736166</td>\n      <td>0.708157</td>\n      <td>0.777945</td>\n      <td>0.755290</td>\n      <td>...</td>\n      <td>0.712722</td>\n      <td>0.715455</td>\n      <td>0.705317</td>\n      <td>0.713190</td>\n      <td>0.749315</td>\n      <td>0.732745</td>\n      <td>0.702732</td>\n      <td>0.738184</td>\n      <td>0.719991</td>\n      <td>0.014345</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.009207</td>\n      <td>0.001330</td>\n      <td>0.003094</td>\n      <td>0.001758</td>\n      <td>7</td>\n      <td>{'n_features_to_select': 7}</td>\n      <td>0.719465</td>\n      <td>0.695793</td>\n      <td>0.775019</td>\n      <td>0.758520</td>\n      <td>...</td>\n      <td>0.715199</td>\n      <td>0.717462</td>\n      <td>0.706869</td>\n      <td>0.715224</td>\n      <td>0.750409</td>\n      <td>0.733976</td>\n      <td>0.705980</td>\n      <td>0.740035</td>\n      <td>0.722226</td>\n      <td>0.013842</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.008405</td>\n      <td>0.002007</td>\n      <td>0.002295</td>\n      <td>0.000461</td>\n      <td>8</td>\n      <td>{'n_features_to_select': 8}</td>\n      <td>0.714166</td>\n      <td>0.671223</td>\n      <td>0.775634</td>\n      <td>0.758417</td>\n      <td>...</td>\n      <td>0.722086</td>\n      <td>0.724369</td>\n      <td>0.713732</td>\n      <td>0.723439</td>\n      <td>0.752675</td>\n      <td>0.738797</td>\n      <td>0.713807</td>\n      <td>0.744390</td>\n      <td>0.728667</td>\n      <td>0.012203</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.006892</td>\n      <td>0.001511</td>\n      <td>0.002499</td>\n      <td>0.000673</td>\n      <td>9</td>\n      <td>{'n_features_to_select': 9}</td>\n      <td>0.712160</td>\n      <td>0.673564</td>\n      <td>0.769910</td>\n      <td>0.755378</td>\n      <td>...</td>\n      <td>0.723088</td>\n      <td>0.725160</td>\n      <td>0.714349</td>\n      <td>0.724586</td>\n      <td>0.752894</td>\n      <td>0.743385</td>\n      <td>0.714536</td>\n      <td>0.748083</td>\n      <td>0.730064</td>\n      <td>0.012842</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.006702</td>\n      <td>0.001735</td>\n      <td>0.003200</td>\n      <td>0.002963</td>\n      <td>10</td>\n      <td>{'n_features_to_select': 10}</td>\n      <td>0.710441</td>\n      <td>0.681532</td>\n      <td>0.781997</td>\n      <td>0.756918</td>\n      <td>...</td>\n      <td>0.725956</td>\n      <td>0.728834</td>\n      <td>0.717969</td>\n      <td>0.727255</td>\n      <td>0.755867</td>\n      <td>0.743506</td>\n      <td>0.718483</td>\n      <td>0.748130</td>\n      <td>0.732804</td>\n      <td>0.011920</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.006095</td>\n      <td>0.001443</td>\n      <td>0.002601</td>\n      <td>0.000802</td>\n      <td>11</td>\n      <td>{'n_features_to_select': 11}</td>\n      <td>0.709272</td>\n      <td>0.678405</td>\n      <td>0.775438</td>\n      <td>0.756005</td>\n      <td>...</td>\n      <td>0.730828</td>\n      <td>0.729382</td>\n      <td>0.718551</td>\n      <td>0.728120</td>\n      <td>0.757035</td>\n      <td>0.747680</td>\n      <td>0.719197</td>\n      <td>0.750452</td>\n      <td>0.734451</td>\n      <td>0.012394</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.003996</td>\n      <td>0.000630</td>\n      <td>0.002201</td>\n      <td>0.000401</td>\n      <td>12</td>\n      <td>{'n_features_to_select': 12}</td>\n      <td>0.706787</td>\n      <td>0.683852</td>\n      <td>0.776975</td>\n      <td>0.757888</td>\n      <td>...</td>\n      <td>0.731083</td>\n      <td>0.733510</td>\n      <td>0.723233</td>\n      <td>0.730462</td>\n      <td>0.761431</td>\n      <td>0.752822</td>\n      <td>0.725036</td>\n      <td>0.753351</td>\n      <td>0.738302</td>\n      <td>0.012381</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.004291</td>\n      <td>0.001499</td>\n      <td>0.002099</td>\n      <td>0.000538</td>\n      <td>13</td>\n      <td>{'n_features_to_select': 13}</td>\n      <td>0.720316</td>\n      <td>0.667979</td>\n      <td>0.777476</td>\n      <td>0.754316</td>\n      <td>...</td>\n      <td>0.733979</td>\n      <td>0.736713</td>\n      <td>0.724424</td>\n      <td>0.733250</td>\n      <td>0.763980</td>\n      <td>0.753029</td>\n      <td>0.726660</td>\n      <td>0.753366</td>\n      <td>0.740307</td>\n      <td>0.012091</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.003495</td>\n      <td>0.000804</td>\n      <td>0.002302</td>\n      <td>0.000645</td>\n      <td>14</td>\n      <td>{'n_features_to_select': 14}</td>\n      <td>0.720316</td>\n      <td>0.667979</td>\n      <td>0.777476</td>\n      <td>0.754316</td>\n      <td>...</td>\n      <td>0.733979</td>\n      <td>0.736713</td>\n      <td>0.724424</td>\n      <td>0.733250</td>\n      <td>0.763980</td>\n      <td>0.753029</td>\n      <td>0.726660</td>\n      <td>0.753366</td>\n      <td>0.740307</td>\n      <td>0.012091</td>\n    </tr>\n  </tbody>\n</table>\n<p>14 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_25416\\3857925637.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmatplotlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpyplot\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msns\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfigsize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m6\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtitle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Your first polynomial regression – congrats! :)\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msize\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m16\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "#plt.figure(figsize=(10, 6))\n",
    "#plt.title(\"Your first polynomial regression – congrats! :)\", size=16)\n",
    "#plt.scatter(y_test, y_predicted)\n",
    "#plt.plot(y_test, y_predicted, c=\"red\")\n",
    "#plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 97  73]\n",
      " [ 97  55]\n",
      " [ 31  18]\n",
      " [ 80  60]\n",
      " [ 97  84]\n",
      " [ 97  33]\n",
      " [ 13   3]\n",
      " [102  60]\n",
      " [ 70  46]\n",
      " [169 112]\n",
      " [ 86  90]\n",
      " [ 76  45]\n",
      " [ 97  58]\n",
      " [ 87  75]\n",
      " [ 87 103]\n",
      " [ 72  30]\n",
      " [115  50]\n",
      " [ 76  91]\n",
      " [ 80  48]\n",
      " [187  87]\n",
      " [ 80  38]\n",
      " [ 97  68]\n",
      " [150  99]\n",
      " [ 50  61]\n",
      " [ 72  42]\n",
      " [ 69  55]\n",
      " [ 38  24]\n",
      " [ 96  95]\n",
      " [147 106]\n",
      " [  5   6]\n",
      " [147 109]\n",
      " [ 45  28]\n",
      " [ 76  49]\n",
      " [ 97  53]\n",
      " [ 97  43]\n",
      " [ 43  78]\n",
      " [ 31  35]\n",
      " [106  97]\n",
      " [150  92]\n",
      " [ 59  37]\n",
      " [ 97  52]\n",
      " [ 13  11]\n",
      " [126  77]\n",
      " [ 75  65]\n",
      " [ 31   7]\n",
      " [126 105]\n",
      " [114  82]\n",
      " [187 118]\n",
      " [ 97  85]\n",
      " [ 43  34]\n",
      " [166  84]\n",
      " [100  96]\n",
      " [ 72  39]\n",
      " [ 76  70]\n",
      " [ 97  91]\n",
      " [102 106]\n",
      " [102  89]\n",
      " [ 34  47]\n",
      " [187 118]\n",
      " [116  54]\n",
      " [106 101]\n",
      " [  3  20]\n",
      " [100 104]\n",
      " [ 75  43]\n",
      " [180 118]\n",
      " [114  89]\n",
      " [ 87  74]\n",
      " [111  89]\n",
      " [147 100]\n",
      " [  5   8]\n",
      " [ 97  67]\n",
      " [ 73  51]\n",
      " [ 12  11]\n",
      " [166  63]\n",
      " [ 97  80]\n",
      " [ 80  72]\n",
      " [180 117]\n",
      " [ 97  59]\n",
      " [ 80  87]\n",
      " [ 28   4]\n",
      " [187 102]\n",
      " [ 72  26]\n",
      " [ 98  49]\n",
      " [ 86  32]\n",
      " [ 96  15]\n",
      " [164  81]\n",
      " [ 69  36]\n",
      " [ 73  72]\n",
      " [126  83]\n",
      " [ 43  22]\n",
      " [187  86]\n",
      " [126  88]\n",
      " [ 80  74]\n",
      " [ 31  10]\n",
      " [102  53]\n",
      " [100 110]\n",
      " [ 67  98]\n",
      " [130  85]\n",
      " [100 118]\n",
      " [  6   1]\n",
      " [187  69]\n",
      " [116  64]\n",
      " [ 87  86]\n",
      " [147 116]\n",
      " [  6   2]\n",
      " [172 108]\n",
      " [ 97  58]\n",
      " [166  40]\n",
      " [ 72  31]\n",
      " [166  50]\n",
      " [ 43  27]\n",
      " [ 72  23]\n",
      " [166  76]\n",
      " [ 87  37]\n",
      " [111  56]\n",
      " [ 97  90]\n",
      " [ 59  25]\n",
      " [ 72  21]\n",
      " [ 87  57]\n",
      " [ 85  94]\n",
      " [ 27  16]\n",
      " [102  59]\n",
      " [  6   9]\n",
      " [ 69  60]\n",
      " [118  66]\n",
      " [100 107]\n",
      " [102  79]\n",
      " [  7  19]\n",
      " [ 72  39]\n",
      " [187 113]\n",
      " [ 97  41]\n",
      " [ 12  21]\n",
      " [115  42]\n",
      " [ 28  14]\n",
      " [ 24  78]\n",
      " [100  44]\n",
      " [ 50  25]\n",
      " [166  96]\n",
      " [ 50  62]\n",
      " [ 87  93]\n",
      " [ 72  29]\n",
      " [147 111]\n",
      " [111  71]\n",
      " [169 114]\n",
      " [  6   5]\n",
      " [ 38  13]\n",
      " [ 59  26]\n",
      " [  5  12]\n",
      " [ 39   0]\n",
      " [144  87]\n",
      " [187 115]\n",
      " [111  17]]\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aarth\\.conda\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "lab = preprocessing.LabelEncoder()\n",
    "y_train_transformed = lab.fit_transform(y_train)\n",
    "y_test_transformed = lab.fit_transform(y_test)\n",
    "\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(X_train, y_train_transformed)\n",
    "\n",
    "pred_LogReg  = logisticRegr.predict(X_test)\n",
    "print(np.vstack((pred_LogReg,y_test_transformed)).T)\n",
    "\n",
    "\n",
    "score = logisticRegr.score(X_test, y_test_transformed)\n",
    "print(score)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch",
   "language": "python",
   "display_name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
